## Manifold Learning:

Many dimension reduction algorithms work by modeling the manifold on which the training instances lie; this is called Manifold 
learning. It relies on the manifold assumption, also called manifold hypothesis, which holds that most real-world high-dimensional datasets lie close to a much lower-dimensional manifold. This obervation is very often observed.

Siwss roll is an eg of a 2D manifold. A 2D manifold is a 2D shape that can be bent and twisted in a higher-dimensional space. More gen a d-dimensional manifold is a part of n-ndimesnioanl (d<n) space that locally resembles a 2-d dimensional hyperplane.

Assumption in Manifold - The task at hand  (eg, classification or regression) will be simpler if expressed in the lower-dimensional space of the manifold.


In short, if you reduce the dimensionality of your training set before training a model, it will definietly speed up training, but it may not always lead to a better or simpler solution; it all depend on the dataset.
